#!/usr/bin/env bash
# The driver script
usage="ncparallel [OPTIONS...] [-d=DIMNAME] [-p=NP] [-n=NF] COMMAND INPUT1 [INPUT2 ... INPUTN] OUTPUT"
doc="This script splits up an input NetCDF file into chunks, runs a script
on some or all of those chunks in parallel, and merges the results into
an output NetCDF file.

Usage

  $usage

Positional arguments

  COMMAND  A command-line command, e.g. './myscript.sh' or a quoted
           string like 'python file.py'.
  INPUT    The input NetCDF file name(s).
  OUTPUT   The output NetCDF file name.

Optional arguments

  -d=* The dimension name along which we split the file. Defaults to 'lat'.
  -n=* The number of file pieces to generate. Defaults to 8.
  -p=* The maximum number of parallel processes. Defaults to -n but can
       also be smaller.

Flags

  -h   Print this message.
  -r   If passed, the OUTPUT file name comes before the INPUT file name(s)
       when calling this function and when passing arugments to COMMAND.
  -f   If passed and -d is a record (i.e. unlimited) dimension, the dimension
       has fixed length in the OUTPUT file.
  -k   If passed, temporary files and log files are not deleted. By default,
       log files are only kept if a process failed.
  -s   If passed, messages are silenced.
"
# Get arguments
# debug='-D 2'
debug=''
nsplit=8
dimname=lat # can also split along time dimension?
keep=false
reverse=false
silent=false
fixrec=false
dir=${0%/*}
source $dir/header.sh
while [ $# -ne 0 ]; do
  case "$1" in
    -h) echo "$doc" >&2 && exit 0 ;;
    -n=*) nsplit="${1#*=}" ;;
    -d=*) dimname="${1#*=}" ;;
    -p=*) pmax="${1#*=}" ;;
    -f) fixrec=true ;;
    -k) keep=true ;;
    -r) reverse=true ;;
    -s) silent=true ;;
    -*) raise "Unknown argument ${1}." ;;
    *) args+=("$1") ;;
  esac
  shift
done
[ -z "$pmax" ] && pmax=$nsplit # same as number of files

# Set up exit trap
cleanup() {
  signal=$?
  [ -n "$keep" ] && $keep && return
  rm "${outputs[@]}" "${inputs[@]}" 2>/dev/null
  [ "$signal" -eq 0 ] && rm "${logs[@]}"
}


# Variables
cmd="${args[0]}"
args=("${args[@]:1}")
n=${#args[@]}
[ $n -ge 2 ] || raise "At least 2 filenames are required, but got $n: ${args[*]}"
for arg in "${args[@]}"; do
  [ -r "$arg" ] || raise "File \"$arg\" not found."
done
if $reverse; then
  inputs=("${args[@]:1:n-1}")
  output="${args[0]}"
else
  inputs=("${args[@]::n-1}")
  output="${args[n-1]}"
fi
[ ${#inputs[@]} -eq 1 ] || echo "Error: Only one input filename allowed."
input="${inputs[0]}"

# Time format
if $silent; then
  export TIMEFORMAT=$''
else
  export TIMEFORMAT=$'real %3lR user %3lU sys %3lS'
fi

# Special case
if [ $nsplit -eq 1 ]; then
  echo "Warning: You passed -n=1. Not dividing up file."
  if $reverse; then
    $cmd "$output" "${inputs[@]}"
  else
    $cmd "${inputs[@]}" "$output"
  fi
  exit  # with code from command
fi

# Get dimension size by parsing ncks
# Could also parse ncdump, but this script requires NCO already so why not
# See: http://nco.sourceforge.net/nco.html#ncdmnsz
ndim=$(ncks --trd -m -M "$input" | grep -E -i ": ${dimname}, size =" | cut -f 7 -d ' ' | uniq | xargs)
[ -n "$ndim" ] || raise "Dimension ${dimname} not found in filename ${input}."
[[ $ndim =~ ^[0-9]+$ ]] || raise "Got invalid size ${ndim} for dimension ${dimname}."
[ $((ndim % nsplit)) -eq 0 ] || raise "Incompatible dimension size ${ndim} for ${nsplit} splits."

# Optionally fix the record dimension
if $fixrec; then
  ncdump -h "$input" | grep 'UNLIMITED' | grep $dimname &>/dev/null \
    && unlimited=true || unlimited=false
  $unlimited && flag="--fix_rec_dmn $dimname" # required for mppnccombine
fi

#-----------------------------------------------------------------------------#
# New method: Perform ncdivide inline
#-----------------------------------------------------------------------------#
# Generate background processes for each file, for example a python script
# that creates a new NetCDF file from some input NetCDF file.
# WARNING: Make sure that your command preserves the 'domain_decomposition' dimension
# attribute and 'NumFilesInSet' global attribute on the output NetCDF file!
i=1
time {
  $silent || echo "Running '$cmd'"
  for ni in $(seq 1 $nsplit); do
    # Output name
    ifile=${input%.nc}.$(printf "%04d" $((ni-1))).nc
    prefix=${output%.nc} # just trim the extension
    suffix=${ifile:${#ifile}-7} # 0000.nc, 0001.nc, etc.
    ofile=${prefix}.${suffix}
    log=${output%/*}/${suffix%.nc}.log

    # Slice up input file and run command with slice
    d1=$(((ni - 1) * ndim / nsplit))  # e.g. nsplit=10, ndim=200, goes 0, 20, 40, 60
    d2=$((ni * ndim / nsplit - 1))  # e.g. nsplit=10, ndim=200, goes 19, 39, 59
    {
      ncks -O -h $debug \
        --bfr_sz 2000000 --no_tmp_fl --hdr_pad 1000 --no_abc $flag \
        -d $dimname,$d1,$d2 "$input" "$ifile" >&2
      ncatted -O -h \
        -a NumFilesInSet,global,o,l,"$nsplit" \
        -a domain_decomposition,$dimname,o,l,"1,$ndim,$((d1 + 1)),$((d2 + 1))" \
        "$ifile"
      if $reverse; then
        $cmd "$ofile" "$ifile"
      else
        $cmd "$ifile" "$ofile"
      fi
    } &>$log &

    # Store process IDs and output files
    pids+=($!)
    logs+=("$log")
    inputs+=("$ifile")
    outputs+=("$ofile")
    if [ $i -eq $pmax ]; then
      i=1
      pwait "$cmd" "${pids[@]}"
      unset pids
    else
      i=$((i + 1))
    fi
  done
  pwait "$cmd" "${pids[@]}"
}

# Finally combine, and remove the temporary files
# generated for parallel processing
$silent || echo "Combining into file: ${output##*/}"
time {
  $dir/nccombine "$output" "${outputs[@]}" \
    || raise "nccombine failed."
}
exit 0

#-----------------------------------------------------------------------------#
# Old method: Perform nccombine separately
#-----------------------------------------------------------------------------#
## Divide into smaller files and collect names in a bash array
## Format will be input.0000.nc, input.0001.nc, etc.
## TODO: Divide up to n blocks
#$silent || echo "Dividing file: ${input##*/}"
#time {
#  inputs=($($dir/ncdivide -p=$pmax -n=$nsplit -d=$dimname $flags "$input")) \
#    || raise "ncdivide failed."
#}
#
## Generate background processes for each file, for example a python script
## that creates a new NetCDF file from some input NetCDF file.
## WARNING: Make sure that your command preserves the 'domain_decomposition' dimension
## attribute and 'NumFilesInSet' global attribute on the output NetCDF file!
#i=1
#time {
#  $silent || echo "Running $cmd"
#  $silent || echo "Input files: ${inputs[*]##*/}"
#  for ifile in "${inputs[@]}"; do
#    # Output name
#    prefix=${output%.nc} # just trim the extension
#    suffix=${ifile:${#ifile}-7} # 0000.nc, 0001.nc, etc.
#    ofile=${prefix}.${suffix}
#    log=${output%/*}/${suffix%.nc}.log
#
#    # Run command
#    if $reverse; then
#      $cmd "$ofile" "$ifile" &>$log & # trailing ampersand sends process to background
#    else
#      $cmd "$ifile" "$ofile" &>$log & # trailing ampersand sends process to background
#    fi
#
#    # Store process IDs and output files
#    pids+=($!)
#    logs+=("$log")
#    outputs+=("$ofile")
#    if [ $i -eq $pmax ]; then
#      i=1
#      pwait "$cmd" "${pids[@]}"
#      unset pids
#    else
#      i=$((i + 1))
#    fi
#  done
#  pwait "$cmd" "${pids[@]}"
#  $silent || echo "Output files: ${outputs[*]##*/}"
#}
#
## Finally combine, and remove the temporary files
## generated for parallel processing
#$silent || echo "Combining into file: ${output##*/}"
#time {
#  $dir/nccombine "$output" "${outputs[@]}" \
#    || raise "nccombine failed."
#}
#exit 0
